---
title: "431_HW6_Qian Cao"
output: word_document
---

### 6.19 Mean TRAP in young women
```{r}
n=31
x_bar=13.2
p_sd=6.5
moe=qnorm(.975)*p_sd/sqrt(n)
left = x_bar-moe
right = x_bar+moe
```
We are 95% confident that mean TRAP amount in range of `r round(left,1)` and `r round(right,1)`(U/I)  

### 6.33 Required sample size for specific margin
```{r}
moe=1.5
p_sd=6.5
n=((qnorm(.975)*6.5)/moe)^2
```
We require sample size to be `r round(n)` 

### 6.54 Determining Hypotheses
(a): Uo = .96, H0: U = Uo , Ha: U > Uo  
(b): Uo = 75, H0: U = Uo, Ha: U > Uo  
(c): Uo = 0, H0: U = Uo, Ha: U > Uo  

### 6.137 CEO Pay
(a): Sketch Normal curve for 6.9% when H0 is Ture
```{r}
increase_mean = 6.9
sd_increase = 55
U0=0
n=104
sample_mean_sd = 55/sqrt(104)
Z=(increase_mean-U0)/(sample_mean_sd)
from_z=-3
to_z = Z

curve(dnorm(x,0,1),xlim = c(-3,3),main = "Normal distribution")
S.x = c(from_z,seq(from_z,to_z,0.01),to_z)
S.y = c(0,dnorm(seq(from_z,to_z,0.01)),0)
polygon(S.x,S.y,col = "skyblue")
PValue = pnorm(6.9,sample_mean_sd,lower.tail = TRUE)
```

(b): P-Value = `r round(PValue,2)`  

(c): 1_P-Value = `r round(1-PValue,3)` > 0.05, whcih stands for not sigificant, therefore, we fail to reject H0:The CEO's compensation went up    

### 6.141 Simulation study of confidence interval
```{r}
n=15
x_mean  = 20
std = 5
p=.975

lhs = round(x_mean-qnorm(p,0,1)*std/sqrt(n),2)
rhs = round(x_mean+qnorm(p,0,1)*std/sqrt(n),2)

count = 0

for (i in 1:100){
  sample_20 = sample(5:35,15,replace = FALSE)
  mean_sample = mean(sample_20)
  if ((mean_sample >=lhs) && (mean_sample<=rhs)){
  count = count+1  
  }
}
```
Confidence interval is: (`r lhs`,`r rhs`)  
Number of counts for value U=20 in the CI is `r count`  
We are 95% confident that U = 20 is between the CI: (`r lhs`,`r rhs`)  

### 7.27 Uber X Driver earning
(a): Yes, it's proper to use t method, Plot Uber driver earning:  
```{r}
load("~/Documents/MSIT/3. Stats 431/R/Chapter 7/EX07-027UBERX.rda")
earning_rate = `EX07-027UBERX`$Earning
hist(earning_rate)
earning_mean = mean(earning_rate)
earning_n = length(earning_rate)
earning_sd = sd(earning_rate)
earning_se = earning_sd/sqrt(earning_n)
t_score = qt(c(0.025,0.975),df = earning_n-1)
earning_moe_rhs = t_score[2]*earning_se
earning_moe_lhs = t_score[1]*earning_se
```
(b): The estimate earning per hour = `r round(earning_mean,2)`, The margin of error: `r round(earning_moe_rhs,2)`  

(c):95% Confidence Interval: (`r round(earning_mean+earning_moe_lhs,2)` , `r round(earning_mean+earning_moe_rhs,2)`)  

(d): H0: U = 90766 Ha: U!= 90766
```{r}
U0 = 90766
t = (earning_mean - U0/(52*40))/earning_se
P=pt(t,df=earning_n-1,lower.tail = TRUE)*2
```
The P-value = `r P` is small, therefore we reject H0, and in favor to Ha: the conclusion that esitimate is not $90,766


### 7.40 Potential Insurance Fraud
(a): compute mean of difference and sd of differnece 
```{r}
load("~/Documents/MSIT/3. Stats 431/R/Chapter 7/EX07-040JOCKO.rda")
JOCKO_df = `EX07-040JOCKO`
quote_diff = JOCKO_df$Jocko - JOCKO_df$Other
diff_mean = mean(quote_diff)
diff_sd = sd(quote_diff)
```
Mean of difference = `r diff_mean` and STD of difference = `r diff_sd`  

(b): Statistic test with H0: U = U0 and Ha: U != U0, given U0 = 0
```{r}
diff_U0 = 0
diff_n = length(quote_diff)
diff_df = diff_n-1
diff_se = diff_sd/sqrt(diff_n)
diff_t = (diff_mean-diff_U0)/diff_se
diff_P = pt(diff_t,df = diff_df,lower.tail = FALSE)*2
```
The P-Value = `r diff_P`,which is smaller than significance level, therefore, we reject H0, and in favor to Ha that there exists the difference between 2 garages.  

(c): Compute the 95% confidence interval: 
```{r}
diff_t = qt(c(0.025,0.975),df = diff_df)
diff_moe = diff_t*diff_se
CI_lhs = round(diff_mean + diff_moe[1],2)
CI_rhs = round(diff_mean + diff_moe[2],2)
```
CI = (`r CI_lhs`,`r CI_rhs`)

(d): For 1000 repayment requirement, ensure difference between J and normal is no less than 5% significance level:
Let P-Value >= 5%, using one side hypothese U < U0
```{r}
req_n = 1000
req_sd = diff_sd/sqrt(req_n)
req_z = qnorm(0.95,0,1,lower.tail = TRUE)
req_mean = diff_mean+req_z*req_sd
total_repayment = req_mean
```
Using Part (c), we may want to seek `r 1000*CI_rhs`   
But using 1000 filed claims as new samples, I would say taht it's more reasoable to seek:`r round(total_repayment,2)*1000`







```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

